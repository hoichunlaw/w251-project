{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "\n",
    "# function to convert TF tensor to Numpy array\n",
    "def toNumpy(tf_tensor):\n",
    "    \n",
    "    session = tf.keras.backend.get_session()\n",
    "    \n",
    "    np_array = tf_tensor.eval(session=session)\n",
    "    \n",
    "    return np_array\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"data/birdsong-recognition/train_audio/\"\n",
    "BIRDS = os.listdir(audio_path)[0:5]    # start with 5 birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** number of mel bands set to 13 instead of 224, trying to lower dimension of data *****\n",
    "sr = 22050\n",
    "layerMelSpectrogram = Melspectrogram(n_dft=1024, \n",
    "                       n_hop=256,\n",
    "                       input_shape=(1, sr*10),\n",
    "                       padding='same', sr=sr, n_mels=13, fmin=1400, fmax=sr/2,\n",
    "                       power_melgram=2.0, return_decibel_melgram=True,\n",
    "                       trainable_fb=False, trainable_kernel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [07:06<00:00, 85.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# load training data & create MelSpectrogram\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for bird in tqdm(BIRDS):\n",
    "    files = os.listdir(os.path.join(audio_path, bird))\n",
    "    files = [f for f in files if f[0]!=\".\"]\n",
    "    \n",
    "    for file in files:\n",
    "        signal, sr = librosa.load(os.path.join(audio_path, bird, file), duration=10, sr=16000)\n",
    "        \n",
    "        # add 0 padding\n",
    "        signal = list(signal) + [0 for i in range(sr*10 - len(signal))]\n",
    "        \n",
    "        S = layerMelSpectrogram(np.array(signal, dtype=np.float32).reshape(1, 1, -1))\n",
    "        S = toNumpy(S)\n",
    "        S = S.reshape(-1)\n",
    "        \n",
    "        x_train.append(list(S))\n",
    "        y_train.append(bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382, 8125)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check x_train shape\n",
    "x_train = np.array(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382, 8125)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_std = scaler.fit_transform(x_train)\n",
    "x_train_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of latent vector\n",
    "n_z = 16\n",
    "\n",
    "# encoder\n",
    "inputs = Input(shape=(x_train.shape[1],))\n",
    "h_q = Dense(5000, activation='relu')(inputs)\n",
    "mu = Dense(n_z, activation='linear')(h_q)\n",
    "log_sigma_sq = Dense(n_z, activation='linear')(h_q)\n",
    "\n",
    "encoder_out = tf.keras.layers.concatenate([mu, log_sigma_sq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "def sample_z(mu, log_sigma_sq):\n",
    "    eps = tf.random.normal(shape=tf.shape(mu))\n",
    "    return mu + tf.sqrt(tf.exp(log_sigma_sq)) * eps\n",
    "\n",
    "z = sample_z(mu, log_sigma_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "decoder_hidden = Dense(5000, activation='relu')\n",
    "decoder_out = Dense(x_train.shape[1], activation='sigmoid')\n",
    "\n",
    "h_p = decoder_hidden(z)\n",
    "outputs = decoder_out(h_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall VAE model, for reconstruction and training\n",
    "vae = Model(inputs, outputs)\n",
    "\n",
    "# Encoder model, to encode input into latent variable\n",
    "# We use the mean as the output as it is the center point, the representative of the gaussian\n",
    "encoder = Model(inputs, encoder_out)\n",
    "\n",
    "# Generator model, generate new data given latent variable z\n",
    "d_in = Input(shape=(n_z,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true, y_pred):\n",
    "    \"\"\" loss = reconstruction loss + KL divergence for each data in minibatch \"\"\"\n",
    "    \n",
    "    recon_loss = -tf.reduce_sum(y_true * tf.math.log(1e-8 + y_pred) + \n",
    "                                (1-y_true) * tf.math.log(1e-8 + 1 - y_pred), 1)\n",
    "\n",
    "    kl_loss = 0.5 * tf.reduce_sum(tf.exp(log_sigma_sq) + mu**2 - 1. - log_sigma_sq, 1)\n",
    "    \n",
    "    return tf.reduce_mean(recon_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 8125)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 5000)         40630000    input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           80016       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 16)           80016       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_random_normal_2/Ran [(None, 16)]         0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_2 (TensorFlowOp [(None, 16)]         0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_random_normal_2/mul [(None, 16)]         0           tf_op_layer_random_normal_2/Rando\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt_2 (TensorFlowO [(None, 16)]         0           tf_op_layer_Exp_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_random_normal_2 (Te [(None, 16)]         0           tf_op_layer_random_normal_2/mul[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_2 (TensorFlowOp [(None, 16)]         0           tf_op_layer_Sqrt_2[0][0]         \n",
      "                                                                 tf_op_layer_random_normal_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_2 (TensorFlowOp [(None, 16)]         0           dense_14[0][0]                   \n",
      "                                                                 tf_op_layer_mul_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 5000)         85000       tf_op_layer_add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8125)         40633125    dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 81,508,157\n",
      "Trainable params: 81,508,157\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hoichunlaw/opt/anaconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 382 samples\n",
      "Epoch 1/10\n",
      "382/382 [==============================] - 9s 24ms/sample - loss: nan\n",
      "Epoch 2/10\n",
      "382/382 [==============================] - 3s 9ms/sample - loss: nan\n",
      "Epoch 3/10\n",
      "382/382 [==============================] - 4s 9ms/sample - loss: nan\n",
      "Epoch 4/10\n",
      "382/382 [==============================] - 3s 9ms/sample - loss: nan\n",
      "Epoch 5/10\n",
      "382/382 [==============================] - 3s 9ms/sample - loss: nan\n",
      "Epoch 6/10\n",
      "382/382 [==============================] - 4s 9ms/sample - loss: nan\n",
      "Epoch 7/10\n",
      "382/382 [==============================] - 4s 9ms/sample - loss: nan\n",
      "Epoch 8/10\n",
      "382/382 [==============================] - 3s 9ms/sample - loss: nan\n",
      "Epoch 9/10\n",
      "382/382 [==============================] - 3s 9ms/sample - loss: nan\n",
      "Epoch 10/10\n",
      "382/382 [==============================] - 4s 9ms/sample - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fab919a0590>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.config.experimental_run_functions_eagerly(True)\n",
    "vae.reset_states()\n",
    "vae.fit(x_train, x_train, \n",
    "        batch_size=32, \n",
    "        epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('tensorflow_cpu': conda)",
   "language": "python",
   "name": "python37564bittensorflowcpuconda29354b1eeb6a46339c907157af122c74"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
